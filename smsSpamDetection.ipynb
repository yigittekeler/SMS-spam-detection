{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pcx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk kütüphanesini import ediyoruz\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>spam</th>\n",
       "      <td>488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted    \n",
       "                 spam ham\n",
       "actual spam       488   1\n",
       "       ham          2  67"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "\n",
    "#veriyi okuyoruz\n",
    "data = pd.read_table(r'C:\\Users\\pcx\\Desktop\\SMSSpamCollection',names=['label','text'])\n",
    "\n",
    "\n",
    "\n",
    "#ingilizcede stop words olarak geçen ve 'a','when' gibi teoride anlamsız\n",
    "#kelimeleri stringden atmak için kullanacağımız nesneyi oluşturduk.\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "#Stemming işlemi, ek almış bir kelimede bulunabilen ortak ön eklerin ve son eklerin \n",
    "#bir listesini dikkate alarak kelimenin başlangıcını veya sonunu atıp kök halini bulmaya çalışır.\n",
    "porter = nltk.PorterStemmer() \n",
    "\n",
    "#ham veriyi düzenlediğimiz fonksiyon\n",
    "def textDuzenle(text):    \n",
    "    assert(type(text) == str)  # burada text parametresinin string olup olmadığı kontrol edilir\n",
    "    \n",
    "    #alttaki işlemler e_mail adresi,dolar ve euro işareti gibi sembolleri string karşılıklarıyla değiştirmek içindir\n",
    "    duzenli = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr', text)\n",
    "    duzenli = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr',\n",
    "                     duzenli)\n",
    "    duzenli = re.sub(r'£|\\$', 'moneysymb', duzenli)\n",
    "    duzenli= re.sub(\n",
    "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "        'phonenumbr', duzenli)\n",
    "    duzenli = re.sub(r'\\d+(\\.\\d+)?', 'numbr', duzenli)\n",
    "    duzenli= re.sub(r'[^\\w\\d\\s]', ' ', duzenli)\n",
    "    duzenli = re.sub(r'\\s+', ' ', duzenli)\n",
    "    duzenli = re.sub(r'^\\s+|\\s+?$', '', duzenli.lower())\n",
    "    return ' '.join(\n",
    "        porter.stem(term) \n",
    "        for term in duzenli.split()\n",
    "        if term not in set(stop_words)\n",
    "    )\n",
    "\n",
    "# veri setimizde mail içeriğinin bulunduğu text kısmına yazdığımız fonskiyonu uyguluyoruz.\n",
    "data['text'] = data['text'].apply(textDuzenle)\n",
    "\n",
    "# train test split işlemine bağımsız değişken olarak text'i, bağımsız değişken olarak label'ı(ham or spam) gönderiyoruz\n",
    "# test_size bize verinin yüzde kaçlık kısmında test yapılacağını gösterir. Biz yüzde 10'luk kısmını test için ayırıyoruz\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size = 0.1, random_state = 1)\n",
    "\n",
    "# bu aşamada x_train olarak elde ettiğimiz öğrenme verisini TfidVectorizer sınıfının fit_transform metoduyla tdf-if\n",
    "# bilgilerini içeren bir sparse matris haline dönüştürüyoruz.\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# burada bir svm(support vector machine) oluşturulur ve bu model elde ettiğimiz eğitim verimizle eğitilir\n",
    "svm = svm.SVC(C=1000)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# burayı testing setimizi test etmek için kullanıyoruz\n",
    "X_test = vectorizer.transform(X_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "\n",
    "\n",
    "# Burada confusioun matrisi satır ve sütun isimleriyle beraber bir data frame'e aktardık.\n",
    "confusionMatrix=pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    index=[['actual', 'actual'], ['spam', 'ham']],\n",
    "    columns=[['predicted', 'predicted'], ['spam', 'ham']]\n",
    ")\n",
    "# Bu dataframe'i yazıdırıyoruz.\n",
    "confusionMatrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00       489\n",
      "        spam       0.99      0.97      0.98        69\n",
      "\n",
      "    accuracy                           0.99       558\n",
      "   macro avg       0.99      0.98      0.99       558\n",
      "weighted avg       0.99      0.99      0.99       558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# burada sınıflandırma sonucu oluşan değerleri yorumlamak için kullanılan bazı parametreleri buluyoruz\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred)  \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9946236559139785\n"
     ]
    }
   ],
   "source": [
    "# burada sınıflandırma verilerinin accuracy oranını buluyoruz\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)  \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
